{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b6a83-4fc7-4201-a3d2-826222c5bf5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "459e662c-d082-4c6f-bdd0-6aa88bc49440",
   "metadata": {},
   "source": [
    "### Настройка подключения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a21bf98d-1729-4a61-bc02-7e9263502328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Window, Row\n",
    "from pyspark.sql.functions import (\n",
    "    current_timestamp, current_date, date_format, col, sum, avg, median, count, lit, expr, row_number, desc, when\n",
    ")\n",
    "from datetime import date\n",
    "\n",
    "# Создаем SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Postgres-Spark\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-42.7.4.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Параметры подключения\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/dwh\"\n",
    "connection_properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"postgres\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb7587f-c737-4d50-aff2-057b7fa2858a",
   "metadata": {},
   "source": [
    "### Загрузка источников"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "744f791d-8a04-4480-8576-674177c2b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table(schema, table):\n",
    "    return spark.read.jdbc(\n",
    "        url=jdbc_url,\n",
    "        table=f\"{schema}.{table}\",\n",
    "        properties=connection_properties\n",
    "    )\n",
    "\n",
    "def write_table(df, schema, table, mode=\"append\"):\n",
    "    df.write.jdbc(\n",
    "        url=jdbc_url,\n",
    "        table=f\"{schema}.{table}\",\n",
    "        mode=mode,\n",
    "        properties=connection_properties\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8424bfb1-8244-4fc9-9395-3690d237ca08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+---------------------+------------+------------+--------------+-------------------+------------------+-------------------+----------+--------------------+--------------------+------------+-------------+-----------+----------------+----------------+-----------------+-----------------+\n",
      "|order_id|order_created_date|order_completion_date|order_status|craftsman_id|craftsman_name|  craftsman_address|craftsman_birthday|    craftsman_email|product_id|        product_name| product_description|product_type|product_price|customer_id|   customer_name|customer_address|customer_birthday|   customer_email|\n",
      "+--------+------------------+---------------------+------------+------------+--------------+-------------------+------------------+-------------------+----------+--------------------+--------------------+------------+-------------+-----------+----------------+----------------+-----------------+-----------------+\n",
      "|      86|        2022-07-18|           2022-07-21|        done|          86| Nolana Lorait|16 Washington Alley|        2003-09-24|gkembrey2e@digg.com|        86|HandMade Unisex B...|Black solid mediu...|     clothes|           11|         86|Giacinta Kembrey| 2 Swallow Alley|       1997-01-18|gkembrey2e@si.edu|\n",
      "+--------+------------------+---------------------+------------+------------+--------------+-------------------+------------------+-------------------+----------+--------------------+--------------------+------------+-------------+-----------+----------------+----------------+-----------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Чтение данных\n",
    "df_sources = {\n",
    "    \"source1\": read_table(\"source1\", \"craft_market_wide\"),\n",
    "    \"source2_masters_products\": read_table(\"source2\", \"craft_market_masters_products\"),\n",
    "    \"source2_orders_customers\": read_table(\"source2\", \"craft_market_orders_customers\"),\n",
    "    \"source3_orders\": read_table(\"source3\", \"craft_market_orders\"),\n",
    "    \"source3_craftsmans\": read_table(\"source3\", \"craft_market_craftsmans\"),\n",
    "    \"source3_customers\": read_table(\"source3\", \"craft_market_customers\")\n",
    "}\n",
    "\n",
    "# Объединение данных из разных источников\n",
    "def combine_sources():\n",
    "    columns = [\n",
    "        'order_id', 'order_created_date', 'order_completion_date', 'order_status', 'craftsman_id',\n",
    "        'craftsman_name', 'craftsman_address', 'craftsman_birthday', 'craftsman_email', 'product_id',\n",
    "        'product_name', 'product_description', 'product_type', 'product_price', 'customer_id',\n",
    "        'customer_name', 'customer_address', 'customer_birthday', 'customer_email'\n",
    "    ]\n",
    "    \n",
    "    # source1\n",
    "    source1_df = df_sources[\"source1\"].select(columns)\n",
    "    \n",
    "    # source2\n",
    "    source2_df = df_sources[\"source2_masters_products\"] \\\n",
    "        .join(df_sources[\"source2_orders_customers\"], on=[\n",
    "            \"product_id\", \"craftsman_id\"], how=\"inner\") \\\n",
    "        .select(columns)\n",
    "\n",
    "    # source3\n",
    "    source3_df = df_sources[\"source3_orders\"] \\\n",
    "        .join(df_sources[\"source3_craftsmans\"], on=\"craftsman_id\", how=\"inner\") \\\n",
    "        .join(df_sources[\"source3_customers\"], on=\"customer_id\", how=\"inner\") \\\n",
    "        .select(columns)\n",
    "\n",
    "    # Объединение всех источников\n",
    "    return source1_df.union(source2_df).union(source3_df).distinct()\n",
    "\n",
    "# Обработка объединенных данных\n",
    "combined_df = combine_sources()\n",
    "\n",
    "# Показать результаты объединения\n",
    "combined_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5568ee-2391-4d71-ba75-2e325acb3803",
   "metadata": {},
   "source": [
    "### Формирование таблиц измерений и фактов в DWH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b02973-01e3-479e-a5a5-cffea2922772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "dwh_customers_df = read_table(\"dwh\", \"d_customers\")\n",
    "dwh_products_df = read_table(\"dwh\", \"d_products\")\n",
    "dwh_craftsmans_df = read_table(\"dwh\", \"d_craftsmans\")\n",
    "dwh_orders_df = read_table(\"dwh\", \"f_orders\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4fc96e-6a3f-4782-ab55-c8cd46ac1172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+--------------------+-----------------+--------------------+--------------------+\n",
      "|customer_id|  customer_name|    customer_address|customer_birthday|      customer_email|           load_dttm|\n",
      "+-----------+---------------+--------------------+-----------------+--------------------+--------------------+\n",
      "|          1|Ariel Hidderley|3616 American Ash...|       1995-05-21|ahidderleyik@tiny...|2025-01-22 00:42:...|\n",
      "|          2|    Del Kindred|220 Grasskamp Par...|       1993-06-03|     dkindredki@g.co|2025-01-22 00:42:...|\n",
      "|          3|    Dynah Lough|286 Mitchell Terrace|       1999-04-17|dloughlz@blogspot...|2025-01-22 00:42:...|\n",
      "|          4| Goldina Napper|    592 Nova Parkway|       2004-11-08|gnapperp7@hatena....|2025-01-22 00:42:...|\n",
      "|          5|  Dinny McGlynn|      1 Sommers Hill|       2000-10-15|dmcglynn6i@archiv...|2025-01-22 00:42:...|\n",
      "+-----------+---------------+--------------------+-----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------+---------------+--------------------+-----------------+--------------------+--------------------+\n",
      "|customer_id|  customer_name|    customer_address|customer_birthday|      customer_email|           load_dttm|\n",
      "+-----------+---------------+--------------------+-----------------+--------------------+--------------------+\n",
      "|          1|Ariel Hidderley|3616 American Ash...|       1995-05-21|ahidderleyik@tiny...|2025-01-22 00:42:...|\n",
      "+-----------+---------------+--------------------+-----------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Чтение текущих данных из DWH\n",
    "existing_customers_df = read_table(\"dwh\", \"d_customers\")\n",
    "\n",
    "# Указание интересующих нас колонок\n",
    "customer_columns = ['customer_name', 'customer_address', 'customer_birthday', 'customer_email']\n",
    "\n",
    "# Фильтрация данных: сохраняем только уникальные записи из исходного DataFrame\n",
    "new_customer_data = combined_df.select(customer_columns).distinct()\n",
    "\n",
    "# Определение новых записей путем удаления уже существующих данных\n",
    "unique_new_customers = new_customer_data.join(\n",
    "    existing_customers_df.select(customer_columns),\n",
    "    on=customer_columns,\n",
    "    how='left_anti'\n",
    ").withColumn(\"load_dttm\", F.current_timestamp())  # Используем load_dttm вместо load_timestamp\n",
    "\n",
    "# Кэшируем DataFrame, чтобы избежать потери данных\n",
    "unique_new_customers = unique_new_customers.cache()\n",
    "\n",
    "# Записываем только уникальные записи в таблицу DWH\n",
    "write_table(unique_new_customers, \"dwh\", \"d_customers\")\n",
    "\n",
    "# Проверяем первые несколько строк таблицы после записи\n",
    "updated_customers_df = read_table(\"dwh\", \"d_customers\")\n",
    "updated_customers_df.show(5)\n",
    "\n",
    "enriched_customers_df = unique_new_customers.alias(\"new_customers\").join(\n",
    "    existing_customers_df.alias(\"d_customers\"),\n",
    "    on=[\n",
    "        F.col(\"new_customers.customer_name\") == F.col(\"d_customers.customer_name\"),\n",
    "        F.col(\"new_customers.customer_address\") == F.col(\"d_customers.customer_address\"),\n",
    "        F.col(\"new_customers.customer_birthday\") == F.col(\"d_customers.customer_birthday\"),\n",
    "        F.col(\"new_customers.customer_email\") == F.col(\"d_customers.customer_email\")\n",
    "    ],\n",
    "    how='left'\n",
    ").select(\n",
    "    F.col(\"d_customers.customer_id\").alias(\"customer_id\"),\n",
    "    F.col(\"new_customers.customer_name\"),\n",
    "    F.col(\"new_customers.customer_address\"),\n",
    "    F.col(\"new_customers.customer_birthday\"),\n",
    "    F.col(\"new_customers.customer_email\"),\n",
    "    F.col(\"new_customers.load_dttm\")  # Сохраняем поле load_dttm\n",
    ")\n",
    "\n",
    "# Просмотр результата с присоединенным customer_id\n",
    "enriched_customers_df.show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1325fb8-6d8c-429b-897e-29d1696ebfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|product_id|        product_name| product_description|        product_type|product_price|           load_dttm|\n",
      "+----------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|         1|        Pathiri Podi|Pathiri is a trad...|Foodgrains, Oil &...|           12|2025-01-22 00:42:...|\n",
      "|         2|HandMade Gold-Pla...|Gold-plated and b...|             clothes|           10|2025-01-22 00:42:...|\n",
      "|         3|HandMade Plus Siz...|Blue and beige la...|             clothes|           19|2025-01-22 00:42:...|\n",
      "|         4|Foot Pumice Paddl...|HandMade foot pum...|    Beauty & Hygiene|           25|2025-01-22 00:42:...|\n",
      "|         5|Bergamot & Cedarw...|HandMade Luxury S...|    Beauty & Hygiene|           31|2025-01-22 00:42:...|\n",
      "+----------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+------------+--------------------+--------------------+-------------+--------------------+\n",
      "|product_id|product_name| product_description|        product_type|product_price|           load_dttm|\n",
      "+----------+------------+--------------------+--------------------+-------------+--------------------+\n",
      "|         1|Pathiri Podi|Pathiri is a trad...|Foodgrains, Oil &...|           12|2025-01-22 00:42:...|\n",
      "+----------+------------+--------------------+--------------------+-------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Чтение текущих данных из DWH\n",
    "existing_products_df = read_table(\"dwh\", \"d_products\")\n",
    "\n",
    "# Указание интересующих нас колонок\n",
    "product_columns = ['product_name', 'product_description', 'product_type', 'product_price']\n",
    "\n",
    "# Фильтрация данных: сохраняем только уникальные записи из исходного DataFrame\n",
    "new_product_data = combined_df.select(product_columns).distinct()\n",
    "\n",
    "# Определение новых записей путем удаления уже существующих данных\n",
    "unique_new_products = new_product_data.join(\n",
    "    existing_products_df.select(product_columns),\n",
    "    on=product_columns,\n",
    "    how='left_anti'\n",
    ").withColumn(\"load_dttm\", F.current_timestamp())  # Используем load_dttm\n",
    "\n",
    "# Кэшируем DataFrame, чтобы избежать потери данных\n",
    "unique_new_products = unique_new_products.cache()\n",
    "\n",
    "# Записываем только уникальные записи в таблицу DWH\n",
    "write_table(unique_new_products, \"dwh\", \"d_products\")\n",
    "\n",
    "# Проверяем первые несколько строк таблицы после записи\n",
    "updated_products_df = read_table(\"dwh\", \"d_products\")\n",
    "updated_products_df.show(5)\n",
    "\n",
    "\n",
    "enriched_products_df = unique_new_products.alias(\"new_products\").join(\n",
    "    existing_products_df.alias(\"d_products\"),\n",
    "    on=[\n",
    "        F.col(\"new_products.product_name\") == F.col(\"d_products.product_name\"),\n",
    "        F.col(\"new_products.product_description\") == F.col(\"d_products.product_description\"),\n",
    "        F.col(\"new_products.product_type\") == F.col(\"d_products.product_type\"),\n",
    "        F.col(\"new_products.product_price\") == F.col(\"d_products.product_price\")\n",
    "    ],\n",
    "    how='left'\n",
    ").select(\n",
    "    F.col(\"d_products.product_id\").alias(\"product_id\"),\n",
    "    F.col(\"new_products.product_name\"),\n",
    "    F.col(\"new_products.product_description\"),\n",
    "    F.col(\"new_products.product_type\"),\n",
    "    F.col(\"new_products.product_price\"),\n",
    "    F.col(\"new_products.load_dttm\")  # Сохраняем поле load_dttm\n",
    ")\n",
    "\n",
    "# Просмотр результата с присоединенным product_id\n",
    "enriched_products_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faaea714-a09a-47d8-91a9-ce9a612726c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+--------------------+------------------+--------------------+--------------------+\n",
      "|craftsman_id| craftsman_name|   craftsman_address|craftsman_birthday|     craftsman_email|           load_dttm|\n",
      "+------------+---------------+--------------------+------------------+--------------------+--------------------+\n",
      "|           1| Khalil Heining|  83956 Manley Plaza|        1998-02-08|ymcwhorter17@inte...|2025-01-22 00:42:...|\n",
      "|           2|     Jake Draye|      2 Bluestem Way|        2003-08-01|dwannes8v@newsvin...|2025-01-22 00:42:...|\n",
      "|           3|  Gustave Irwin|   54700 Swallow Way|        1992-09-02|jwherritc1@cornel...|2025-01-22 00:42:...|\n",
      "|           4|  Zelma Scarffe|5560 Blackbird Plaza|        2000-05-24|ccripinh2@list-ma...|2025-01-22 00:42:...|\n",
      "|           5|Katlin Guilloud|       9659 8th Lane|        1992-01-08|bsheberjf@pcworld...|2025-01-22 00:42:...|\n",
      "+------------+---------------+--------------------+------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+--------------+------------------+------------------+--------------------+--------------------+\n",
      "|craftsman_id|craftsman_name| craftsman_address|craftsman_birthday|     craftsman_email|           load_dttm|\n",
      "+------------+--------------+------------------+------------------+--------------------+--------------------+\n",
      "|           1|Khalil Heining|83956 Manley Plaza|        1998-02-08|ymcwhorter17@inte...|2025-01-22 00:42:...|\n",
      "+------------+--------------+------------------+------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Чтение текущих данных из DWH\n",
    "existing_craftsmans_df = read_table(\"dwh\", \"d_craftsmans\")\n",
    "\n",
    "# Указание интересующих нас колонок\n",
    "craftsmans_columns = ['craftsman_name', 'craftsman_address', 'craftsman_birthday', 'craftsman_email']\n",
    "\n",
    "# Фильтрация данных: сохраняем только уникальные записи из исходного DataFrame\n",
    "new_craftsman_data = combined_df.select(craftsmans_columns).distinct()\n",
    "\n",
    "# Определение новых записей путем удаления уже существующих данных\n",
    "unique_new_craftsmans = new_craftsman_data.join(\n",
    "    existing_craftsmans_df.select(craftsmans_columns),\n",
    "    on=craftsmans_columns,\n",
    "    how='left_anti'\n",
    ").withColumn(\"load_dttm\", F.current_timestamp())  # Используем load_dttm\n",
    "\n",
    "# Кэшируем DataFrame, чтобы избежать потери данных\n",
    "unique_new_craftsmans = unique_new_craftsmans.cache()\n",
    "\n",
    "# Записываем только уникальные записи в таблицу DWH\n",
    "write_table(unique_new_craftsmans, \"dwh\", \"d_craftsmans\")\n",
    "\n",
    "# Проверяем первые несколько строк таблицы после записи\n",
    "updated_craftsmans_df = read_table(\"dwh\", \"d_craftsmans\")\n",
    "updated_craftsmans_df.show(5)\n",
    "\n",
    "enriched_craftsmans_df = unique_new_craftsmans.alias(\"new_craftsmans\").join(\n",
    "    existing_craftsmans_df.alias(\"d_craftsmans\"),\n",
    "    on=[\n",
    "        F.col(\"new_craftsmans.craftsman_name\") == F.col(\"d_craftsmans.craftsman_name\"),\n",
    "        F.col(\"new_craftsmans.craftsman_address\") == F.col(\"d_craftsmans.craftsman_address\"),\n",
    "        F.col(\"new_craftsmans.craftsman_birthday\") == F.col(\"d_craftsmans.craftsman_birthday\"),\n",
    "        F.col(\"new_craftsmans.craftsman_email\") == F.col(\"d_craftsmans.craftsman_email\")\n",
    "    ],\n",
    "    how='left'\n",
    ").select(\n",
    "    F.col(\"d_craftsmans.craftsman_id\").alias(\"craftsman_id\"),\n",
    "    F.col(\"new_craftsmans.craftsman_name\"),\n",
    "    F.col(\"new_craftsmans.craftsman_address\"),\n",
    "    F.col(\"new_craftsmans.craftsman_birthday\"),\n",
    "    F.col(\"new_craftsmans.craftsman_email\"),\n",
    "    F.col(\"new_craftsmans.load_dttm\")  # Сохраняем поле load_dttm\n",
    ")\n",
    "\n",
    "# Просмотр результата с присоединенным craftsman_id\n",
    "enriched_craftsmans_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0509e71-2436-492a-ac98-7984e705400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+-----------+------------------+---------------------+------------+--------------------+\n",
      "|order_id|product_id|craftsman_id|customer_id|order_created_date|order_completion_date|order_status|           load_dttm|\n",
      "+--------+----------+------------+-----------+------------------+---------------------+------------+--------------------+\n",
      "|       1|       157|         157|        157|        2022-06-25|           2022-06-29|        done|2025-01-22 00:42:...|\n",
      "|       2|       805|         805|        805|        2022-09-05|           2022-09-07|        done|2025-01-22 00:42:...|\n",
      "|       3|       122|         122|        122|        2022-07-09|           2022-07-11|        done|2025-01-22 00:42:...|\n",
      "|       4|       630|         630|        630|        2022-08-16|           2022-08-17|        done|2025-01-22 00:42:...|\n",
      "|       5|        11|          11|         11|        2022-05-12|           2022-05-14|        done|2025-01-22 00:42:...|\n",
      "+--------+----------+------------+-----------+------------------+---------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+----------+------------+-----------+------------------+---------------------+------------+--------------------+\n",
      "|order_id|product_id|craftsman_id|customer_id|order_created_date|order_completion_date|order_status|           load_dttm|\n",
      "+--------+----------+------------+-----------+------------------+---------------------+------------+--------------------+\n",
      "|       1|       157|         157|        157|        2022-06-25|           2022-06-29|        done|2025-01-22 00:42:...|\n",
      "+--------+----------+------------+-----------+------------------+---------------------+------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Чтение текущих данных из DWH\n",
    "existing_orders_df = read_table(\"dwh\", \"f_orders\")\n",
    "\n",
    "# Указание интересующих нас колонок\n",
    "orders_columns = ['product_id', 'craftsman_id', 'customer_id', 'order_created_date', 'order_completion_date', 'order_status']\n",
    "\n",
    "# Фильтрация данных: сохраняем только уникальные записи из исходного DataFrame\n",
    "new_order_data = combined_df.select(orders_columns).distinct()\n",
    "\n",
    "# Определение новых записей путем удаления уже существующих данных\n",
    "unique_new_orders = new_order_data.join(\n",
    "    existing_orders_df.select(orders_columns),\n",
    "    on=orders_columns,\n",
    "    how='left_anti'\n",
    ").withColumn(\"load_dttm\", F.current_timestamp())  # Используем load_dttm\n",
    "\n",
    "# Кэшируем DataFrame, чтобы избежать потери данных\n",
    "unique_new_orders = unique_new_orders.cache()\n",
    "\n",
    "# Записываем только уникальные записи в таблицу DWH\n",
    "write_table(unique_new_orders, \"dwh\", \"f_orders\")\n",
    "\n",
    "# Проверяем первые несколько строк таблицы после записи\n",
    "updated_orders_df = read_table(\"dwh\", \"f_orders\")\n",
    "updated_orders_df.show(5)\n",
    "\n",
    "enriched_orders_df = unique_new_orders.alias(\"new_orders\").join(\n",
    "    existing_orders_df.alias(\"f_orders\"),\n",
    "    on=[\n",
    "        F.col(\"new_orders.product_id\") == F.col(\"f_orders.product_id\"),\n",
    "        F.col(\"new_orders.craftsman_id\") == F.col(\"f_orders.craftsman_id\"),\n",
    "        F.col(\"new_orders.customer_id\") == F.col(\"f_orders.customer_id\"),\n",
    "        F.col(\"new_orders.order_created_date\") == F.col(\"f_orders.order_created_date\"),\n",
    "        F.col(\"new_orders.order_completion_date\") == F.col(\"f_orders.order_completion_date\"),\n",
    "        F.col(\"new_orders.order_status\") == F.col(\"f_orders.order_status\")\n",
    "    ],\n",
    "    how='left'\n",
    ").select(\n",
    "    F.col(\"f_orders.order_id\").alias(\"order_id\"),\n",
    "    F.col(\"new_orders.product_id\"),\n",
    "    F.col(\"new_orders.craftsman_id\"),\n",
    "    F.col(\"new_orders.customer_id\"),\n",
    "    F.col(\"new_orders.order_created_date\"),\n",
    "    F.col(\"new_orders.order_completion_date\"),\n",
    "    F.col(\"new_orders.order_status\"),\n",
    "    F.col(\"new_orders.load_dttm\")  \n",
    ")\n",
    "\n",
    "# Просмотр результата с присоединенным order_id\n",
    "enriched_orders_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b4b50-fbb0-4ba2-bc89-8e3bd1c120ac",
   "metadata": {},
   "source": [
    "### Заполнение витрины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "298d608c-3665-4e12-b570-0e513a4138d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>craftsman_id</th>\n",
       "      <th>report_period</th>\n",
       "      <th>craftsman_name</th>\n",
       "      <th>craftsman_address</th>\n",
       "      <th>craftsman_birthday</th>\n",
       "      <th>craftsman_email</th>\n",
       "      <th>craftsman_money</th>\n",
       "      <th>platform_money</th>\n",
       "      <th>count_order</th>\n",
       "      <th>avg_price_order</th>\n",
       "      <th>avg_age_customer</th>\n",
       "      <th>median_time_order_completed</th>\n",
       "      <th>count_order_created</th>\n",
       "      <th>count_order_in_progress</th>\n",
       "      <th>count_order_delivery</th>\n",
       "      <th>count_order_done</th>\n",
       "      <th>count_order_not_done</th>\n",
       "      <th>top_product_category</th>\n",
       "      <th>load_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>2022-07</td>\n",
       "      <td>Jeanelle Healing</td>\n",
       "      <td>575 Graedel Park</td>\n",
       "      <td>1999-03-25</td>\n",
       "      <td>csprason3@soup.io</td>\n",
       "      <td>79.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>21.3305950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>clothes</td>\n",
       "      <td>2025-01-22 00:43:29.831006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>Ulberto Duffrie</td>\n",
       "      <td>0 Sommers Way</td>\n",
       "      <td>1992-04-09</td>\n",
       "      <td>pcloneyp2@histats.com</td>\n",
       "      <td>71.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1</td>\n",
       "      <td>79.0</td>\n",
       "      <td>33.2019160000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>clothes</td>\n",
       "      <td>2025-01-22 00:43:29.831006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142</td>\n",
       "      <td>2018-09</td>\n",
       "      <td>Casper Lambrook</td>\n",
       "      <td>14 Luster Lane</td>\n",
       "      <td>2002-04-09</td>\n",
       "      <td>bmckendry2k@java.com</td>\n",
       "      <td>73.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1</td>\n",
       "      <td>82.0</td>\n",
       "      <td>24.5065020000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>clothes</td>\n",
       "      <td>2025-01-22 00:43:29.831006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251</td>\n",
       "      <td>2020-01</td>\n",
       "      <td>Charlean Bendin</td>\n",
       "      <td>302 Mendota Street</td>\n",
       "      <td>1994-06-01</td>\n",
       "      <td>igentrye3@ycombinator.com</td>\n",
       "      <td>49.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>30.2012320000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Beauty &amp; Hygiene</td>\n",
       "      <td>2025-01-22 00:43:29.831006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>480</td>\n",
       "      <td>2022-06</td>\n",
       "      <td>Thornton Tremollet</td>\n",
       "      <td>40 Grasskamp Drive</td>\n",
       "      <td>2003-08-16</td>\n",
       "      <td>imorley28@linkedin.com</td>\n",
       "      <td>64.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>25.4455850000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>clothes</td>\n",
       "      <td>2025-01-22 00:43:29.831006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   craftsman_id report_period      craftsman_name   craftsman_address  \\\n",
       "0            87       2022-07    Jeanelle Healing    575 Graedel Park   \n",
       "1            96       2019-09     Ulberto Duffrie       0 Sommers Way   \n",
       "2           142       2018-09     Casper Lambrook      14 Luster Lane   \n",
       "3           251       2020-01     Charlean Bendin  302 Mendota Street   \n",
       "4           480       2022-06  Thornton Tremollet  40 Grasskamp Drive   \n",
       "\n",
       "  craftsman_birthday            craftsman_email  craftsman_money  \\\n",
       "0         1999-03-25          csprason3@soup.io             79.2   \n",
       "1         1992-04-09      pcloneyp2@histats.com             71.1   \n",
       "2         2002-04-09       bmckendry2k@java.com             73.8   \n",
       "3         1994-06-01  igentrye3@ycombinator.com             49.5   \n",
       "4         2003-08-16     imorley28@linkedin.com             64.8   \n",
       "\n",
       "   platform_money  count_order  avg_price_order avg_age_customer  \\\n",
       "0             8.8            1             88.0    21.3305950000   \n",
       "1             7.9            1             79.0    33.2019160000   \n",
       "2             8.2            1             82.0    24.5065020000   \n",
       "3             5.5            0             55.0    30.2012320000   \n",
       "4             7.2            0             72.0    25.4455850000   \n",
       "\n",
       "   median_time_order_completed  count_order_created  count_order_in_progress  \\\n",
       "0                          1.0                    0                        0   \n",
       "1                          1.0                    0                        0   \n",
       "2                          3.0                    0                        0   \n",
       "3                          NaN                    1                        0   \n",
       "4                          NaN                    0                        0   \n",
       "\n",
       "   count_order_delivery  count_order_done  count_order_not_done  \\\n",
       "0                     0                 1                     0   \n",
       "1                     0                 1                     0   \n",
       "2                     0                 1                     0   \n",
       "3                     0                 0                     1   \n",
       "4                     0                 0                     1   \n",
       "\n",
       "  top_product_category                  load_dttm  \n",
       "0              clothes 2025-01-22 00:43:29.831006  \n",
       "1              clothes 2025-01-22 00:43:29.831006  \n",
       "2              clothes 2025-01-22 00:43:29.831006  \n",
       "3     Beauty & Hygiene 2025-01-22 00:43:29.831006  \n",
       "4              clothes 2025-01-22 00:43:29.831006  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавляем столбец для периода отчета (по месяцу и году)\n",
    "enriched_orders_df = enriched_orders_df.withColumn(\"report_period\", F.date_format(\"order_created_date\", \"yyyy-MM\"))\n",
    "\n",
    "# Создаем окно для нахождения самой популярной категории (по количеству заказов)\n",
    "window_spec = Window.partitionBy(\"craftsman_id\", \"report_period\").orderBy(F.desc(\"count_category\"))\n",
    "\n",
    "# Считаем количество товаров каждой категории для каждого мастера и периода\n",
    "product_category_counts = enriched_orders_df.join(\n",
    "    enriched_products_df.alias(\"products\"),\n",
    "    enriched_orders_df[\"product_id\"] == F.col(\"products.product_id\")\n",
    ").groupBy(\"craftsman_id\", \"report_period\", \"products.product_type\") \\\n",
    "    .agg(F.count(\"products.product_type\").alias(\"count_category\"))\n",
    "\n",
    "# Находим топ-1 категорию для каждого мастера и периода\n",
    "top_categories = product_category_counts.withColumn(\n",
    "    \"row_num\", F.row_number().over(window_spec)\n",
    ").filter(F.col(\"row_num\") == 1).select(\"craftsman_id\", \"report_period\", \"product_type\")\n",
    "\n",
    "# Создаем отчет по данным мастеров, включая агрегированные данные\n",
    "new_craftsman_report_datamart_df = enriched_orders_df.join(\n",
    "    enriched_craftsmans_df.alias(\"craftsmans\"),\n",
    "    enriched_orders_df.craftsman_id == F.col(\"craftsmans.craftsman_id\")\n",
    ").join(\n",
    "    enriched_products_df.alias(\"products\"),\n",
    "    enriched_orders_df.product_id == F.col(\"products.product_id\")\n",
    ").join(\n",
    "    enriched_customers_df.alias(\"customers\"),\n",
    "    enriched_orders_df.customer_id == F.col(\"customers.customer_id\")\n",
    ").groupBy(\n",
    "    F.col(\"craftsmans.craftsman_id\"),\n",
    "    F.col(\"craftsmans.craftsman_name\"),\n",
    "    F.col(\"craftsmans.craftsman_address\"),\n",
    "    F.col(\"craftsmans.craftsman_birthday\"),\n",
    "    F.col(\"craftsmans.craftsman_email\"),\n",
    "    F.col(\"report_period\")\n",
    ").agg(\n",
    "    F.sum(F.col(\"products.product_price\") * 0.9).alias(\"craftsman_money\"),\n",
    "    F.sum(F.col(\"products.product_price\") * 0.1).alias(\"platform_money\"),\n",
    "    F.count(enriched_orders_df.order_id).alias(\"count_order\"),\n",
    "    F.avg(F.col(\"products.product_price\")).alias(\"avg_price_order\"),\n",
    "    F.avg(F.expr(\"DATEDIFF(current_date(), customers.customer_birthday) / 365.25\")).alias(\"avg_age_customer\"),\n",
    "    F.median(F.expr(\"DATEDIFF(order_completion_date, order_created_date)\")).alias(\"median_time_order_completed\"),\n",
    "    F.sum(F.when(enriched_orders_df.order_status == \"created\", 1).otherwise(0)).alias(\"count_order_created\"),\n",
    "    F.sum(F.when(enriched_orders_df.order_status == \"in_progress\", 1).otherwise(0)).alias(\"count_order_in_progress\"),\n",
    "    F.sum(F.when(enriched_orders_df.order_status == \"delivery\", 1).otherwise(0)).alias(\"count_order_delivery\"),\n",
    "    F.sum(F.when(enriched_orders_df.order_status == \"done\", 1).otherwise(0)).alias(\"count_order_done\"),\n",
    "    F.sum(F.when(enriched_orders_df.order_status != \"done\", 1).otherwise(0)).alias(\"count_order_not_done\")\n",
    ")\n",
    "\n",
    "# Присоединяем топ-1 категорию товаров\n",
    "new_craftsman_report_datamart_df = new_craftsman_report_datamart_df.join(\n",
    "    top_categories,\n",
    "    [\"craftsman_id\", \"report_period\"],\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"product_type\", \"top_product_category\")\n",
    "\n",
    "# Добавляем столбец с текущей датой загрузки (опционально)\n",
    "new_craftsman_report_datamart_df = new_craftsman_report_datamart_df.withColumn(\"load_dttm\", F.current_timestamp())\n",
    "\n",
    "# Проверяем результат\n",
    "new_craftsman_report_datamart_df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a0bc5d-106d-4beb-8e72-e544f62b98ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение существующих данных из таблицы craftsman_report_datamart\n",
    "craftsman_report_datamart = read_table(\"dwh\", \"craftsman_report_datamart\")\n",
    "\n",
    "# Ключевые столбцы для идентификации строки\n",
    "key_columns = [\"craftsman_id\", \"report_period\"]\n",
    "\n",
    "# 1. Определяем новые строки (INSERT)\n",
    "# Используем \"left_anti\" join, чтобы найти строки, которые есть в новом датафрейме, но отсутствуют в существующем\n",
    "new_rows_df = new_craftsman_report_datamart_df.join(\n",
    "    craftsman_report_datamart.select(*key_columns),\n",
    "    key_columns,\n",
    "    how=\"left_anti\"\n",
    ")\n",
    "\n",
    "# 2. Определяем обновленные строки (UPDATE)\n",
    "# Используем \"inner\" join, чтобы получить строки, которые присутствуют в обоих датафреймах, и затем фильтруем\n",
    "updated_rows_df = new_craftsman_report_datamart_df.alias(\"new\").join(\n",
    "    craftsman_report_datamart.alias(\"existing\"),\n",
    "    key_columns,\n",
    "    how=\"inner\"\n",
    ").filter(\n",
    "    # Проверяем расхождения в значимых столбцах\n",
    "    (\n",
    "        col(\"new.craftsman_money\") != col(\"existing.craftsman_money\")\n",
    "    ) |\n",
    "    (\n",
    "        col(\"new.platform_money\") != col(\"existing.platform_money\")\n",
    "    ) |\n",
    "    (\n",
    "        col(\"new.count_order\") != col(\"existing.count_order\")\n",
    "    ) |\n",
    "    (\n",
    "        col(\"new.avg_price_order\") != col(\"existing.avg_price_order\")\n",
    "    ) |\n",
    "    (\n",
    "        col(\"new.avg_age_customer\") != col(\"existing.avg_age_customer\")\n",
    "    ) |\n",
    "    (\n",
    "        col(\"new.median_time_order_completed\") != col(\"existing.median_time_order_completed\")\n",
    "    ) |\n",
    "    (\n",
    "        col(\"new.count_order_created\") != col(\"existing.count_order_created\")\n",
    "    ) |\n",
    "    (\n",
    "        col(\"new.count_order_in_progress\") != col(\"existing.count_order_in_progress\")\n",
    "    ) |\n",
    "    (\n",
    "        col(\"new.count_order_delivery\") != col(\"existing.count_order_delivery\")\n",
    "    ) |\n",
    "    (\n",
    "        col(\"new.count_order_done\") != col(\"existing.count_order_done\")\n",
    "    ) |\n",
    "    (\n",
    "        col(\"new.count_order_not_done\") != col(\"existing.count_order_not_done\")\n",
    "    ) |\n",
    "    (\n",
    "        col(\"new.top_product_category\") != col(\"existing.top_product_category\")\n",
    "    )\n",
    ").select(\"new.*\")\n",
    "\n",
    "# Результат: новый датафрейм с новыми и обновленными строками\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d40ee0e-6142-4751-ae2f-c0854575a18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[craftsman_id: bigint, report_period: string, craftsman_name: string, craftsman_address: string, craftsman_birthday: date, craftsman_email: string, craftsman_money: double, platform_money: double, count_order: bigint, avg_price_order: double, avg_age_customer: decimal(22,10), median_time_order_completed: double, count_order_created: bigint, count_order_in_progress: bigint, count_order_delivery: bigint, count_order_done: bigint, count_order_not_done: bigint, top_product_category: string, load_dttm: timestamp]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_craftsman_report_datamart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a69b1f24-c086-41f6-8223-efbbb5dbea73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "588bdb4e-ff17-435c-b260-d78d827fbecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def update_existing_rows(df, schema, table):\n",
    "    # Преобразуем DataFrame в список словарей\n",
    "    rows = df.collect()\n",
    "    update_query = f\"\"\"\n",
    "    UPDATE {schema}.{table} AS target\n",
    "    SET craftsman_money = data.craftsman_money,\n",
    "        platform_money = data.platform_money,\n",
    "        count_order = data.count_order,\n",
    "        avg_price_order = data.avg_price_order,\n",
    "        avg_age_customer = data.avg_age_customer,\n",
    "        median_time_order_completed = data.median_time_order_completed,\n",
    "        count_order_created = data.count_order_created,\n",
    "        count_order_in_progress = data.count_order_in_progress,\n",
    "        count_order_delivery = data.count_order_delivery,\n",
    "        count_order_done = data.count_order_done,\n",
    "        count_order_not_done = data.count_order_not_done,\n",
    "        top_product_category = data.top_product_category,\n",
    "        load_dttm = data.load_dttm\n",
    "    FROM (VALUES %s) AS data (\n",
    "        craftsman_id, report_period, craftsman_money, platform_money, count_order, avg_price_order,\n",
    "        avg_age_customer, median_time_order_completed, count_order_created, count_order_in_progress,\n",
    "        count_order_delivery, count_order_done, count_order_not_done, top_product_category, load_dttm\n",
    "    )\n",
    "    WHERE target.craftsman_id = data.craftsman_id AND target.report_period = data.report_period\n",
    "    \"\"\"\n",
    "    \n",
    "    # Устанавливаем соединение с Postgres\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"postgres\",\n",
    "        user=\"postgres\",\n",
    "        password=\"postgres\",\n",
    "        host=\"postgres\",\n",
    "        port=\"5432\"\n",
    "    )\n",
    "    with conn.cursor() as cursor:\n",
    "        # Формируем данные для VALUES\n",
    "        values = [\n",
    "            (\n",
    "                row[\"craftsman_id\"], row[\"report_period\"], row[\"craftsman_money\"], row[\"platform_money\"],\n",
    "                row[\"count_order\"], row[\"avg_price_order\"], row[\"avg_age_customer\"], \n",
    "                row[\"median_time_order_completed\"], row[\"count_order_created\"],\n",
    "                row[\"count_order_in_progress\"], row[\"count_order_delivery\"], row[\"count_order_done\"],\n",
    "                row[\"count_order_not_done\"], row[\"top_product_category\"], row[\"load_dttm\"]\n",
    "            )\n",
    "            for row in rows\n",
    "        ]\n",
    "        execute_values(cursor, update_query, values)\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d59ce8f4-20a8-44b8-957e-06b583cd5623",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_table(new_rows_df.drop(\"load_dttm\"), \"dwh\", \"craftsman_report_datamart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "632a119f-77a8-4022-90c9-2ac794fd4e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id| load_dttm|\n",
      "+---+----------+\n",
      "|  1|2025-01-22|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_dates_dma = read_table(\"dwh\", \"load_dates_craftsman_report_datamart\")\n",
    "\n",
    "load_dates_data = [Row(load_dttm=date.today())]  # Используем текущую дату из модуля datetime\n",
    "load_dates_df = spark.createDataFrame(load_dates_data).exceptAll(load_dates_dma.select('load_dttm'))\n",
    "\n",
    "\n",
    "write_table(load_dates_df, \"dwh\", \"load_dates_craftsman_report_datamart\")\n",
    "\n",
    "read_table(\"dwh\", \"load_dates_craftsman_report_datamart\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d85d7-7c88-43cc-9579-358b527b2bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
